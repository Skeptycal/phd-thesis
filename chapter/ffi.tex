\input{chapter-header.tex}
% =============================================================================

\chapter{Validation: FFI}
\chaplabel{ffi}
\minitoc

% ===========================================================================
\section{Introduction}
\seclabel{introduction}
% ===========================================================================

\begin{figure*}[ht]
	\centering
	\includegraphics[width=\textwidth]{extensionComparison}
	\caption{Comparing different extension mechanisms: a) library implemented completely at language-side running on a standard VM, b) language using features from a VM extension, c) language using features from a VM plugin, d) language-side implementation of an extension.}
	\figlabel{extensionComparison}
\end{figure*}

Currently, more and more code is produced and available through reusable libraries such as OpenGL\footnote{\url{http://www.opengl.org/}} or Cairo\footnote{\url{http://cairographics.org/}}.
While working on your own projects using dynamic languages, it is crucial to be able to use such existing libraries with little effort.
Multiple solutions exist to achieve access to an external library from dynamic languages that are executed on the top of a virtual machine (VM) such as Pharo\footnote{\url{http://pharo.org/}}, Lua\footnote{\url{http://lua.org/}} or Python\footnote{\url{http://python.org/}}.
Figure~\figref{extensionComparison} depicts four possibilities of dealing with new or external libraries in a high-level language.

\paragraph{Language-side Library.}
One solution is to re-implement a library completely at language-side (cf. Figure~\figref{extensionComparison}.a).
Even though this is the most flexible solution, this is often not an option, neither from the technical point of view (performance penalty), nor from the economic point of view (development time and costs).

\paragraph{VM Extension.}
The second one (\figref{extensionComparison}.b) is to do a \emph{VM extension} providing new primitives that the high-level language uses to access the native external library.
This solution is generally efficient since the external library may be statically compiled within the VM.
However a tight integration into the VM also means more dependencies and a different development environment than the final product at language-side.

\paragraph{VM Plugin.}
The third solution (\figref{extensionComparison}.c) is similar to the previous one but the extension is factored out of the VM as a \emph{plugin}.
This solution implies again a lot of low-level development at VM-level that must be done for each external library we want to use.
Additionally we have to adapt the plugin for all platforms on which the VM is supposed to run on.

\paragraph{FFI.}
A higher-level solution is to define \emph{Foreign Function Interfaces} (FFIs) (cf. Figure~\figref{extensionComparison}.d).
The main advantage of this approach is that once a VM is FFI-enabled, only a language extension (no VM-level code) is needed to provide access to new native libraries.
From the portability point of view, only the generic FFI VM-plugin has to be implemented on all platforms.

% Challenges & Goals
Implementing an FFI library is a challenging task because of its antagonist goals:
\begin{itemize}
    \item it must be flexible enough to easily bind to external libraries and also express complex foreign calls regarding the memory management or the type conversions (marshalling);
    \item it must be well integrated with the language (objects, reflection, garbage collector);
    \item it must be efficient.
\end{itemize}
%
Existing FFI libraries of dynamic languages all have different designs and implementations because of the trade-offs they made regarding these goals and challenges.
Typical choices are resorting purely to the VM-level and thus sacrificing flexibility.
The inverse of this approach exists as well: FFIs can be implemented almost completely at language-side but at a significant performance loss.
Both these pitfalls are presented in more detail in Section~\secref{evaluation}.


% list shortcomings of typical implementations (C-FFI vs ALIEN)
% - too low-level (C-FFI) fast in simple examples, complex calls not possible
% - too high-level (ALIEN) slow in simple examples, quite slow in complex ones
% - missing specific code generation
% - missing JIT interaction for speed (like LuaJIT, org.vmmagic)

% Alien and C-FFI run in the same Pharo image as NativeBoost allowing a much closer comparison.
% Alien FFI is implemented almost completely at language-side, much like NativeBoost. However, as the following benchmarks will stress, it also suffers from performance loss.
% On the other end there is C-FFI which is faster than Alien but by far not as flexible. For instance only primitive types are handled directly.


This paper presents \NBFFI\footnote{\url{http://code.google.com/p/nativeboost}} an FFI library at language-side for Pharo that supports callouts and callbacks, which we present in Section~\secref{nutshell}.
There are at least two other existing FFI libraries in Pharo worth mentioning: C-FFI and Alien.
Nevertheless, they both present shortcomings.
C-FFI is fast because it is mostly implemented at VM-level, however it is limited when it comes to do complex calls that involve non-primitive types or when we want to define new data types.
On the opposite, Alien FFI is flexible enough to define any kind of data conversion or new types directly at language-side but it is slower than C-FFI because it is mostly implemented at language-side.
In essence, \NBFFI combines the flexibility and extensibility of Alien that uses language-side definition for marshalling and the speed of C-FFI which is implemented at VM-level.
The main originalities of \NBFFI are:

\begin{description}
	\item[Extensibility.] \NBFFI relies on as few VM primitives as possible (5 primitives), essentially to call native code.  Therefore, most of the implementation resides at language-side, even low-level mechanisms. That makes \NBFFI easily extensible because its implementation can be changed at any time, without needing to update the runtime (VM). It also presents a noticeable philosophical shift, how we want to extend our language in future. A traditional approach is to implement most low-level features at VM-side and provide interfaces to the language-side.
But that comes at cost of less flexibility and longer development and release cycles. On the opposite, we argue that extending language features, even low-level ones, should be done at language-side instead. This results in higher flexibility and without incurring high runtime costs which usually happen when using high-level languages such as Smalltalk.
	\item[Language-side extension.] Accessing a new external library using \NBFFI involves a reduced amount of work since it is only a matter of writing a language-side extension.
	\item[Performance.] Despite the fact it is implemented mostly at language-side, \NBFFI achieves superior performance compared to other FFI implementations running Pharo.
    This is essentially because it uses automatic and transparent native code generation at language-side for marshalling.
\end{description}

%In the following section we present the language-side code that one should write to achieve to interact with external libraries with \NBFFI.
%We then compare performance of \NBFFI with three other FFI implementations in Section~\secref{evaluation}.
%The following Section~\secref{internals} gives more insights on the \NB.
%After the related work presented in Section~\secref{relatedWork} and we conclude this paper in Section~\secref{conclusion}.


% ===========================================================================
\section{\NBFFI: an Introduction}
\seclabel{nutshell}
% ===========================================================================

This section gives an overview of the code that should be written at language-side
to enable interactions with external libraries.

\subsection{Simple Callout}

Listing~\lstref{clock} shows the code of a regular Smalltalk method named \ttt{ticksSinceStart} that defines a callout to the \ttt{clock} function of the \texttt{libc}.
\NB imposes no constraint on the class in which such a binding should be defined.
However, this method must be annotated with a specific pragma (such as \ttt{<primitive:module:>}) which specifies that a native call should be performed using the \NB plugin.

\begin{stcode}[
	label={lst:clock},
	caption={\NBFFI example of callout declaration to the \ttt{clock} function of the \texttt{libc}}]{0}
ticksSinceStart
	<primitive: #primitiveNativeCall
	 module: #NativeBoostPlugin>
	^ self
		nbCall: #(uint clock ())
		module: NativeBoost CLibrary
\end{stcode}

The external function call is then described using the \ttt{nbCall:module:} message.
The first parameter (\ttt{\#nbCall:}) is an array that describes the signature of C function to callout.
Basically, this array contains the description of a C function prototype, which is very close to normal C syntax.
The return type is first described (\ttt{uint} in this example\footnote{The return type of the \texttt{clock} function is \ttt{clock\_t}, but we deliberately used \ttt{uint} in this first example for the sake of simplicity even if it is possible to define a constant type in \NB.}), then the name of the function (\ttt{clock}) and finally the list of parameters (an empty array in this example since \ttt{clock} does not have any).
The second argument, \ttt{\#module:} is the module name, its full path or its handle if already loaded, where to look up the given function.
This example uses a convenience method of \NB named \ttt{CLibrary} to obtain a handle to the standard C library.

% ===========================================================================
\subsection{Callout with Parameters}

% - explain argument detection (match var names)
Figure~\figref{nativeBoostSyntax} presents the general syntax of \NBFFI through an example of a callout to the \ttt{abs} function of the \texttt{libc}.
The \ttt{abs:} method has one argument named \ttt{anInteger} (cf. \ding{182}).
This method uses the pragma \ttt{<primitive:module:error:>} which indicates that the \texttt{\#primitiveNativeCall} of the \texttt{\#NativeBoostPlugin} should be called when this method is executed (cf. \ding{183}).
An \texttt{errorCode} is returned by this primitive if it fails and the regular Smalltalk code below is executed (cf. \ding{184}).
The main difference with the previous example is that the \texttt{abs} function takes one integer parameter.
In this example, the array \texttt{\#(uint abs(int anInteger))} passed as argument to \texttt{\#nbCall:} contains two important information (cf. \ding{185}).
First, the types annotations such as the return type (\texttt{uint} in both examples) and arguments type (\texttt{int} in this example).
These types annotations are then used by \NBFFI to automatically do the marshalling between C and Pharo values as illustrated by the next example.
Second, the values to be passed when calling out.
In this example, \texttt{anInteger} refers to the argument of the \ttt{abs} method, meaning that the value of this variable should be passed to the \texttt{abs} C function.
Finally, this \texttt{abs} function is looked up in the \texttt{libc} whose an handle is passed in the \texttt{module:} parameter (cf. \ding{186}).
% A library can be designated either by its file path on disk or its memory address.
% \begin{stcode}[
% 	label={lst:abs},
% 	caption={Example of callout to the \ttt{abs} function}]{0}
% abs: anInteger
% 	<primitive: #primitiveNativeCall
% 	 module: #NativeBoostPlugin>
%
% 	^ self
% 		nbCall: #(uint abs(int anInteger))
% 		module: NativeBoost CLibrary
% \end{stcode}
%
% - explain syntax in picture (line plus arrows)
\begin{figure}[H]
	\centering
	\includegraphics{nativeBoostSyntax}
	%\nocaptionrule
	%\captionsetup{singlelinecheck=off}
	\caption[\NB basic method]{Example of the general \NBFFI callout syntax}
	\figlabel{nativeBoostSyntax}
\end{figure}

% ===========================================================================
\subsection{Automatic Marshalling of Known Types}

Listing~\lstref{getenv} shows a callout declaration to the \texttt{getenv} function that takes one parameter.

\begin{stcode}[
	label={lst:getenv},
	caption={Example of callout to \ttt{getenv}}]{0}
getenv: name
	<primitive: #primitiveNativeCall
	 module: #NativeBoostPlugin>

	^ self
		nbCall: #(String getenv(String name)
		module: NativeBoost CLibrary
\end{stcode}

In this example, the \NB type specified for the parameter is \texttt{String} instead of \texttt{char*} as specified by the standard \texttt{libc} documentation.
This is on purpose because strings in C are sequences of characters (\ttt{char*}) but they must be terminated with the special character: \cnull.
Specifying \texttt{String} in the \texttt{\#nbCall:} array will make \NB to automatically do the arguments conversion from Smalltalk strings to C strings (\cnull terminated \texttt{char*}).
It means that the string passed will be put in an external C \ttt{char} array and a \cnull character will be added to it at the end.
This array will be automatically released after the call returned.
This is an example of automatic memory management of \NB that can also be controlled if needed.
Obviously, the opposite conversion happens for the returned value and the method returns a Smalltalk String.
This example shows that \NBFFI accepts literals, local and instance variable names in callout declarations and it uses their type annotation to achieve the appropriate data conversion.
Table~\tabref{nbPrimitiveTypes} shows the default and automatic data conversions achieved by \NBFFI.

\begin{table}[hbt]
    \centering
    \begin{tabular}{rll}
        Primitive Type       & Smalltalk Type \\\midrule
        \ttt{uint}   & \ttt{Integer} \\
        \ttt{int}    & \ttt{Integer} \\
        \ttt{String} & \ttt{ByteString} \\
        \ttt{bool}   & \ttt{Boolean} \\
        \ttt{float}  & \ttt{Float} \\
        \ttt{char}   & \ttt{Character} \\
        \ttt{oop}    & \ttt{Object}
    \end{tabular}
    \caption{Default \NBFFI mappings between C/primitive types and high-level types. Note that \ttt{oop} is not a real primitive type as no marshalling is applied and the raw pointer is directly exposed to Pharo.}
    \tablabel{nbPrimitiveTypes}
\end{table}
Listing~\lstref{setenv} shows another example to callout the \texttt{setenv} function.
The return value will be converted to a Smalltalk \texttt{Boolean}.
The two first parameters are specified as \texttt{String} and will be automatically transformed in \texttt{char*} with an ending \cnull character.
The last parameter is \texttt{1}, a Smalltalk literal value without any type specification and \NB translates it as an \texttt{int} by default.

\begin{stcode}[
	label={lst:setenv},
	caption={Example of callout to \ttt{setenv}}]{0}
setenv: name value: value
	<primitive: #primitiveNativeCall
	 module: #NativeBoostPlugin>

	^ self
		nbCall: #(Boolean setenv(String name,
								 String value,
								 1)
		module: NativeBoost CLibrary
\end{stcode}

Another interesting example of automatic marshalling is to define the \ttt{abs} method (cf. Figure~\figref{nativeBoostSyntax}) in the \ttt{SmallInteger} class and passing \texttt{self} as argument in the callout. In such case, \NB automatically converts \texttt{self} (which is a SmallInteger) into an \texttt{int}.
This list of mapping is not exhaustive and \NB also supports the definition of new data types and new conversions into more complex C types such as structures (cf. Section~\secref{internals}).



% memory alloc & structs
\begin{table}[t]
    \centering
    \begin{tabular}{lcccc}
                    &  Memory 	& Address & Marshalling & Constraint  \\\midrule
C-managed struct 	&  C heap  	& fixed & passed by reference & must be freed \\
Pharo-managed struct & Object memory & variable & passed by reference & may move \\
& & & or passed by copy & costly\\
    \end{tabular}
    \caption{Wrapping structures possibilities in \NB}
    \tablabel{wrappingstruct}
\end{table}

% ===========================================================================
\subsection{Supporting new types}\seclabel{newtypes}

The strength of language-side FFIs appears when it comes to do callouts with new data types involved.
\NBFFI supports different possibilities to interact with new types.

\paragraph{Declaring structures.}
For example, the Cairo library\footnote{\url{http://cairographics.org}} provides complex structures such as \texttt{cairo\_surface\_t} and functions to manipulate this data type. % which makes field access useless.
Listing~\lstref{AthensCairoSurface} shows how to write a regular Smalltalk class to wrap a C structure.
\NB only requires a class-side method named \texttt{asNBExternalType:} that describes how to marshall this type back and forth from native code.
In this example, we use existing marshalling mechanism defined in \texttt{NBExternalObjectType} that just copies the structure's pointer and stores it in an instance variable named \ttt{handle}.

\begin{stcode}[
	label={lst:AthensCairoSurface},
	caption={Example of C structure wrapping in \NB}]{0}
AthensSurface subclass: #AthensCairoSurface
	instanceVariableNames: 'handle'.

AthensCairoSurface class>>asNBExternalType: gen
	"handle iv holds my address (cairo_surface_t)"
	^ NBExternalObjectType objectClass: self
\end{stcode}

\paragraph{Callout with structures.}
Listing~\lstref{calloutOpaqueStruct} shows a callout definition to the \texttt{cairo\_image\_surface\_create} function that returns a \ttt{cairo\_surface\_t*} data type.
In this code example, the return type is \texttt{AthensCairoSurface} directly (not a pointer).
When returning from this callout, \NB creates an instance of \texttt{AthensCairoSurface} and the marshalling mechanism  stores the returned address in the \texttt{handle} instance variable of this object.

\begin{stcode}[
	label={lst:calloutOpaqueStruct},
	caption={Example of returning a structure by reference}]{0}
primImage: aFormat width: aWidth height: aHeight
	<primitive: #primitiveNativeCall
	 module: #NativeBoostPlugin
     error: errorCode>

	^self nbCall: #(AthensCairoSurface
		cairo_image_surface_create (int aFormat,
									int aWidth,
									int aHeight) )
\end{stcode}

Conversely, passing an \texttt{AthensCairoSurface} object as a parameter in a callout makes its pointer stored in its \texttt{handle} iv (cf. Listing~\lstref{calloutOpaqueStructParameter}) to be passed.
Since the parameter type is \ttt{AthensCairoSurface} in the callout definition, \NB also ensures that the passed object is really an instance of this class.
If it is not, the callout fails before executing the external function because passing it an address on a non-expected data could lead to unpredicted behavior.

\begin{stcode}[
	label={lst:calloutOpaqueStructParameter},
	caption={Example of passing a structure by reference}]{0}
primCreate: cairoSurface
	<primitive: #primitiveNativeCall
	 module: #NativeBoostPlugin>

	^self nbCall: #(
        AthensCairoCanvas cairo_create (
                  AthensCairoSurface cairoSurface))
\end{stcode}


\paragraph{Accessing structure fields.}
In \NB, one can directly access the fields of a structure if needed, even if it is not a good practice from the data encapsulation point of view.
Nevertheless, it may be mandatory to interact with some native libraries that do not provide all the necessary functions to manipulate the structure.
Listing~\lstref{cairo_c_definition} shows an example of a C struct type definition for \texttt{cairo\_matrix\_t}.

\begin{ccode}[
	label={lst:cairo_c_definition},
	caption={Example external type to convert back and forth with the Cairo library}]{0}
typedef struct {
    double xx; double yx;
    double xy; double yy;
    double x0; double y0;
} cairo_matrix_t;
\end{ccode}

Listing~\lstref{AthensCairoMatrix} shows that the \texttt{NBExternalStructure} of \NBFFI can be subclassed to define new types such as \texttt{AthensCairoMatrix}.
The description of the fields (types and names) of this structure is provided by the \texttt{fieldsDesc} method on the class side.
Given this description, \NB lazily generates field accessors on the instance side using the field names.

\begin{stcode}[
	label={lst:AthensCairoMatrix},
	caption={Example of \NBFFI definition of an \texttt{ExternalStructure}}]{0}
NBExternalStructure
    variableByteSubclass: #AthensCairoMatrix.

AthensCairoMatrix class>>fieldsDesc
	^ #(  double sx; double shx;
		  double shy; double sy;
		  double x; double y;  )
\end{stcode}

Listing~\lstref{cairoCallouts} shows a callout definition to the
 \texttt{cairo\_matrix\_multiply} function passing \texttt{self} as argument with the type \ttt{AthensCairoMatrix*}.
\NB handles the marshalling of this object to a struct as defined in the \texttt{fieldsDesc}.
% The interesting point is that the called function \ttt{cairo\_matrix\_multiply} stores its result in the first argument i.e. the receiver object.

\begin{stcode}[
	label={lst:cairoCallouts},
	caption={Example of callouts using \ttt{cairo\_matrix\_t}}]{0}
AthensCairoMatrix>>primMultiplyBy: m
	<primitive: #primitiveNativeCall
	 module: #NativeBoostPlugin
     error: errorCode>

"C signature"
"void cairo_matrix_multiply (
                     cairo_matrix_t *result,
                     const cairo_matrix_t *a,
                     const cairo_matrix_t *b );"
	^self nbCall: #(void   cairo_matrix_multiply
		(AthensCairoMatrix * self,
		AthensCairoMatrix * m ,
		AthensCairoMatrix * self ) )
\end{stcode}


\paragraph{Memory management of structures.}
Table~\tabref{wrappingstruct} shows a comparison between C-managed and Pharo-managed structures.
The first ones are allocated in the C heap.
Their addresses are fixed and they are passed by reference during a callout.
But the programmer must free them by hand when they are not needed.
The second ones are allocated in the Pharo object-memory.
Their addresses are variable since their enclosing object may be moved by the garbage collector.
They can either passed by copy which is costly or by reference.
Passing a reference may lead to problems is the C function stores the address and try to access it later on since the address may changed.


% ===========================================================================
\subsection{Callbacks}

\NB supports callbacks from native code.
This means it is possible for a C-function to call back into the Pharo runtime and activate code.
We will use the simple \ttt{qsort} C-function to illustrate this use-case.
\ttt{qsort} sorts a given array according to the results of a compare function.
Instead of using a C-function to compare the elements we will use a callback to invoke a Pharo block which will compare the two arguments.
%
\begin{stcode}[
	label={lst:calloutWithCallback},
	caption={Example of callout passing a callback for \ttt{qsort}}]{0}
bytes := #[ 120 12 1 15 ].
callback := QSortCallback on: [ :a :b |
				(a byteAt: 0) - (b byteAt: 0) ].

self ffiQSort: bytes
	 length: bytes size
	 compareWith: callback
\end{stcode}
%
Code \lstref{calloutWithCallback} shows the primary Pharo method for invoking \ttt{qsort} with a \ttt{QSortCallback} instance for the compare function.
In this example \ttt{qsort} will invoke run the Pharo code inside the callback block to compare the elements in the \ttt{bytes} array.

To define a callback in \NB we have to create a specific subclasses for each callback with different argument types.
%
\begin{stcode}[
	label={lst:callbackDefinition},
	caption={Example of callback definition}]{0}

NBFFICallback
    subclass: #QSortCallback.

NBFFICallback class>>signature
	^#(int (NBExternalAddress a, NBExternalAddress b))
\end{stcode}
%
Code \lstref{callbackDefinition} shows \ttt{QSortCallback} which takes two generic external addresses as arguments.
These are the argument types that are being passed to the sort block in Example \lstref{calloutWithCallback}.
%
\begin{stcode}[
	label={lst:qsort},
	caption={Example of callout passing a callback}]{0}
ffiQSort: base len: size compare: qsortCallback
	<primitive: #primitiveNativeCall
	 module: #NativeBoostPlugin>

	"C qsort signature"
	"void qsort(
		void *base,
		size_t nel,
		size_t width,
		int (*compar)(const void *, const void *));"

	^ self
		options: #( optMayGC )
		nbCall: #(void qsort (
					NBExternalAddress array,
					ulong size,
					1, "sizeof an element"
					QSortCallback qsortCallback))
		module: NativeBoost CLibrary
\end{stcode}
%
The last missing piece in this example is the callout definition shown in Code \lstref{qsort}.
The \NB callout specifies the callback arguments by using \ttt{QSortCallback}.

%\begin{enumerate}
%	\item Define a callback by subclassing NBCallback and overriding \ttt{\#fnSpec} method that defines de C signature of the callback
	% Redefining callback signature.
% A callback uses a lazy-initialization scheme to generate a common marshalling code which will be used by all instances of specific callback class.
% So, changing a callback signature (by changing its #fnSpec method) will not have an immediate effect, if you already created at least a single instance of it.
% To make changes take effect, you must restart an image.

%	\item Define a callout as previously but passing a callback as argument using its class name as argument type.

% !!Note!! A special care must be taken for all functions which may make callbacks!
% In the above qsort() example, you can see an additional option for external call - #optMayGC, which tells a code generator to call an external function via call gate (a special stub which handling a code relocation caused by GC). Thats it, for any external functions, which may call the callback you must pass this option.
% Rationale: since most of external functions don't make any callbacks (and so has no chance to trigger GC), using this option by default will be an overkill, which will just spend extra CPU cycles for nothing.
% However, if you omit this option when calling the function(s) which may call back, expect a hard crash(es) to happen.

%	\item instantiate the callback giving it a block.
	% To use callbacks, you must instantiate it first by passing block as an argument:
% mycallback := MyCallback on: someBlock.

% The block is the closure which will be evaluated when callback function get called, so the block must take same number of arguments as specified in #fnSpec method, and its evaluation result must yield a value which can be converted back C type value, which you speficied as a return type of callback function.
% For example, if callback signature is 'int (int foo , float bar )' , we can create a callback with following block closure:

% mycallback := MyCallback on: [:foo :bar |  (foo + bar ) asInteger ].


\paragraph{Callback lifetime.}
Each time a new callback is instantiated it reserves a small amount of external memory which is freed once the callback is no longer used.
This is done automatically using object finalization hooks..


% ===========================================================================
\subsection{Overview of \NBFFI Internals}
% - explain how code is generated in simple steps, not going into details

This section provides an overview of the internal machinery of \NBFFI though it is not mandatory to know it in order to use it as demonstrated by previous examples.

\paragraph{General Architecture.}
Figure~\figref{nbArchitecture} describes the general architecture of \NB.
Most code resides at language-side, nevertheless some generic extensions (primitives) to the VM are necessary to activate native code.
At language-side, callouts are declared with \NBFFI which processes them and dynamically generates x86 native code using the \texttt{AsmJit} library.
This native code is responsible of the marshalling and calling the external function.
\NB then uses a primitive to activate this native code.

\begin{figure}[h]
	\centering
	\includegraphics[scale=1.1]{nbArchitecture}
	\caption{\NB main components that major part of the code resides at language-side.}
	\figlabel{nbArchitecture}
\end{figure}

% General FFI overview and difference of NB
\begin{figure*}[t]
	\centering
	\includegraphics[width=\textwidth]{ffiOverview}
	\caption{Comparison of FFI calls propagation in \NBFFI and a typical VM plugin-based implementation. \NB resorts to VM-level only for the native-code activation, whereas typical implementations cross this barrier much earlier.}
	\figlabel{ffi}
\end{figure*}

\paragraph{Callout propagation.}
Figure~\figref{ffi} shows a comparison of the resolution of a FFI call both in \NBFFI and a plugin-based FFI.
At step 1, a FFI call is emitted.
The \NBFFI call is mostly processed at language-side and it is only during step 4 that a primitive is called and the VM effectively does the external call by executing the native code.
On the opposite, a plugin-based FFI call already crossed the low-level frontier in step 2 resulting that part of the type conversion process (marshalling) is already done in the VM code.
In \NBFFI, doing most of the FFI call processing at language-side makes easier to keep control, redefine or adapt it if needed.

% ===========================================================================
\section{\NBFFI Evaluation}
\seclabel{evaluation}
% ===========================================================================

In this section we compare \NB with other FFI implementations.
\begin{description}
	\item[Alien FFI:] An FFI implementation for Squeak/Pharo that focuses on the language-side. All marshalling happens transparently at language-side.
	\item[C-FFI:] A C based FFI implementation for Squeak/Pharo that performs all marshalling operations at VM-side.
	\item[LuaJIT:] A fast Lua implementation that has a close FFI integration with JIT interaction.
\end{description}

\paragraph{Choice of FFI Implementations.}
To evaluate \NB we explicitly target FFI implementations running on the same platform, hence we can rule out additional performance differences.
Alien and C-FFI run in the same Pharo image as \NB allowing a much closer comparison.

Alien FFI is implemented almost completely at language-side, much like \NB.
However, as the following benchmarks will stress, it also suffers from performance loss.

On the other end there is C-FFI which is faster than Alien but by far not as flexible. For instance only primitive types are handled directly.

As the third implementation we chose Lua. Lua is widely used as scripting language in game development.
Hence much care has been taken to closely integrate Lua into C and C++ environments.
LuaJIT integrates an FFI library that generates the native code for marshalling and directly inlines C functions callout in the JIT-compiled code.

\paragraph{Evaluation Procedure.}
To compare the different FFI approaches we measure 100 times the accumulative time spent to perform $1'000'000$ callouts of the given function.
From the 100 probes we show the average and the standard deviation for a $68\%$ confidence interval in a gaussian distribution.
To exclude the calling and loop overhead we subtract from each evaluation the time spent in the same setup, but without the FFI call.
The final deviation displayed is the arithmetic average of the measured deviation of the base and the callout measurement.

The three Smalltalk FFI solutions (\NB, Alien, C-FFI) are evaluated on the very same Pharo 1.4 (version 14458) image on a Pharo VM (version of May 5. 2013).
For the Lua benchmarks we use LuaJIT 2.0.1.
The benchmarks are performed under the constant conditions on a MacBook Pro.
Even though a standalone machine could improve the performance we are only interested in the relative performance of each implementation.


\paragraph{Choice of Callouts.}
We chose a set of representative C functions to stress different aspects of an FFI implementation.
We start with simple functions that require little marshalling efforts and thus mainly focus on the activation performance and callout overhead.
Later we measure more complex C functions that return complex types and thus stress the marshalling infrastructure.

% ===========================================================================
\subsection{Callout Overhead}
The first set of FFI callouts show mainly the overhead of the FFI infrastructure to perform the callout.

For the first FFI evaluation we measure the execution time for a \ttt{clock()} callout.
The C function takes no argument and returns an integer thus guaranteeing a minimal overhead for marshalling and performing the callout.
%
\begin{table}[H]
    \centering
    \begin{tabular}{rlr}
                    & Call Time                        & Relative Time \\\midrule
        \NB         & \ttt{492.13} $\pm$ \ttt{0.73} ms  & $1.0 \times$ \\
        Alien       & \ttt{606.6 } $\pm$ \ttt{1.9 } ms  & $\approx 1.2\times$ \\
        C-FFI       & \ttt{541.77} $\pm$ \ttt{0.88} ms  & $\approx 1.1\times$ \\
        LuaJIT     & \ttt{343.0 } $\pm$ \ttt{1.2 } ms  & $\approx 0.7\times$
    \end{tabular}
    \caption{Speed comparison of an \ttt{uint clock(void)} FFI call (see Code~\lstref{clock}).}
    \tablabel{performance-clock}
\end{table}
%
\noindent \ttt{abs} is a about the same complexity as the \ttt{clock} function, however accepting a single integer as argument.
%
\begin{table}[h!]
    \centering
    \begin{tabular}{rlr}
                    & Call Time                        & Relative Time \\\midrule
        \NB         & \ttt{ 65.34 } $\pm$ \ttt{0.23 } ms  & $1.00 \times$ \\
        Alien       & \ttt{175.77 } $\pm$ \ttt{0.31 } ms  & $\approx 2.69\times$ \\
        C-FFI       & \ttt{148.77 } $\pm$ \ttt{0.21 } ms  & $\approx 2.27\times$ \\
        LuaJIT\tablefootnote{Downsampled from increased loop size by a factor $100$ to guarantee accuracy.}
                    & \ttt{  }\ttt{  2.035} $\pm$ \ttt{0.015} ms  & $\approx 0.03\times$
    \end{tabular}
    \caption{Speed comparison of an \ttt{int abs(int i)} FFI call (see Figure~\figref{nativeBoostSyntax}).}
    \tablabel{performance-abs}
\end{table}


\paragraph{Evaluation.}
For measuring the calling overhead we chose the \ttt{abs} FFI callout.
This C function is completed in a couple of instructions which in comparison to the conversion and activation effort of the FFI callout is negligible.
In Table~\tabref{performance-abs} we see that \NB is at least a factor two faster than the other \ST implementation.
Yet LuaJIT outperform \NB by an impressive factor 30.
LuaJIT has a really close integration with the JIT and this is what makes the impressive FFI callout results possible.


% ===========================================================================
\subsection{Marshalling Overhead for Primitive Types}
The third example calls \ttt{getenv('PWD')} expecting a string as result:  the path of the current working directory.
Both argument and result have to be converted from high-level strings to C-level zero-terminated strings.
%
\begin{table}[h!]
    \centering
    \begin{tabular}{rlr}
                    & Call Time                        & Relative Time \\\midrule
        \NB         & \ttt{ 105.29} $\pm$ \ttt{0.24} ms  & $1.0 \times$ \\
        Alien       & \ttt{1058.7 } $\pm$ \ttt{2.0 } ms  & $\approx 10.1\times$ \\
        C-FFI       & \ttt{ 282.94} $\pm$ \ttt{0.24} ms  & $\approx 2.7\times$ \\
        LuaJIT\tablefootnote{Downsampled from increased loop size by a factor $10$ to guarantee accuracy.}
                    & \ttt{ }\ttt{ 97.3 } $\pm$ \ttt{5.1 } ms  & $\approx 0.9\times$
    \end{tabular}
    \caption{Speed comparison of an \ttt{char * getenv(char *name)} FFI call (see Code \lstref{getenv}).}
    \tablabel{performance-getenv}
\end{table}

\noindent As a last evaluation of simple C functions with \NB, we call \ttt{printf} with a string and two integers as argument.
The marshalling overhead is less than for the previous \ttt{getenv} example.
However, \ttt{printf} is a more complex C function which requires more time to complete: it has to parse the format string, format the given arguments and pipe the results to standard out.
Hence the relative overhead of an FFI call is reduced.
%
\begin{table}[h!]
    \centering
    \begin{tabular}{rlr}
                    & Call Time                        & Relative Time \\\midrule
        \NB         & \ttt{ 371.03} $\pm$ \ttt{0.51} ms  & $1\times$ \\
        Alien       & \ttt{1412.37} $\pm$ \ttt{0.79} ms  & $\approx 3.8\times$ \\
        C-FFI       & \ttt{ 605.02} $\pm$ \ttt{0.23} ms  & $\approx 1.6\times$ \\
        LuaJIT      & \ttt{ 202.4 } $\pm$ \ttt{2.1 } ms  & $\approx 0.6\times$
    \end{tabular}
    \caption{Speed comparison of an \ttt{int printf(char *name, int num1, int num2)} FFI call}
    \tablabel{performance-printf}
\end{table}

\paragraph{Evaluation.}
Table~\tabref{performance-clock} and Table~\tabref{performance-abs} call C functions that return integers for which the conversion overhead is comparably low.
However we see that Alien compares worse in the case of more complex Strings.
Table~\tabref{performance-getenv} and Table~\tabref{performance-printf} show this behavior.
For the \ttt{getenv} a comparably long string is returned which causes a factor 10 conversion overhead for Alien.


% ===========================================================================
\subsection{Using Complex Structures}

To evaluate the impact of marshalling complex types, we measure the execution time for a callout to \ttt{cairo\_matrix\_multiply}.
In all cases, the allocation time of the structs is not included in the measurement nor their field assignments.
Table \tabref{performance-structs} shows the results.

\begin{table}[h!]
    \centering
    \begin{tabular}{rlr}
                    & Call Time                        & Relative Time \\\midrule
        \NB         & \ttt{ 79.00} $\pm$ \ttt{0.27} ms  & $1.0\times$ \\
        Alien       & \ttt{753.82} $\pm$ \ttt{0.51} ms  & $\approx 9.5\times$ \\
        C-FFI       & \ttt{380.8 } $\pm$ \ttt{2.7 } ms  & $\approx 3.6\times$ \\
        LuaJIT     & \ttt{ }\ttt{ 5.66} $\pm$ \ttt{0.15} ms  & $\approx 0.07\times$
    \end{tabular}
    \caption{Speed comparison of an \ttt{cairo\_matrix\_multiply} FFI call (cf. Listing~\lstref{cairoCallouts})}
 	\tablabel{performance-structs}
\end{table}

\paragraph{Evaluation.}
In Table~\tabref{performance-structs} shows that \NB outperforms the two other Smalltalk implementations.

% ===========================================================================
\subsection{Callbacks}

Table~\tabref{performance-qsort} shows a comparison of \texttt{qsort} callouts passing callbacks.
Callbacks are usually much more slower than callouts.

\begin{table}[H]
    \centering
    \begin{tabular}{rlr}
                    & Call Time                          & Rel. Time \\ \midrule
        \NB         & \ttt{2300.0 } $\pm$ \ttt{1.1 } ms  & $ 1.0 \times$ \\
        Alien       & \ttt{ 600.83} $\pm$ \ttt{0.35} ms  & $\approx 0.26 \times$ \\
        C-FFI       & NA  & NA \\
        LuaJIT     & \ttt{ }\ttt{ 46.13} $\pm$ \ttt{0.62} ms  & $\approx 0.02 \times$\\
		\cmidrule(r){2-3}
	\NB \small{with}\\
	   \small{Native Callbacks}    & \ttt{ }\ttt{ }\ttt{ 4.98} $\pm$ \ttt{0.21} ms  & $\approx 0.002 \times$
    \end{tabular}
    \caption{Speed comparison of a \ttt{qsort} FFI call (cf. Listing~\lstref{calloutWithCallback})}
 	\tablabel{performance-qsort}
\end{table}


\paragraph{Evaluation.}
The results show that \NB callbacks are currently slower than Alien's ones.
This is because Alien relies on specific VM support for callbacks making their activation faster (context creation and stack pages integration).
On the opposite, \NB currently uses small support from the VM side and even do part of the work at image side.
This \ttt{qsort} demonstrates the worst case because it implies a lot of activations of the callback.
For each of these calls, \NB creates a context and make the VM switch to it.
To really demonstrate that these context switches are the bottleneck, Table~\tabref{performance-qsort} also shows the result of doing the same benchmark in \NB but using a native callback i.e. containing native code.
We do not argue here that callbacks should be implemented in native code but that \NB support for callback can be optimized to reach Alien's performance at least.

% ===========================================================================
\section{\NBFFI Implementation Details}
\seclabel{internals}
% ===========================================================================
% mostly recycle section 4.1 and 4.2 from the paper

The following subsections will first focus on the high-level, language-side aspects of \NB, such as native code generation and marshalling.
As a second part we describe implementation details of the low-level extensions, such as the \NB primitives and the JIT interaction.

% ===========================================================================
\subsection{Generating Native Code}
\seclabel{generating}

In \NB all code generation happens transparently at language-side.
The various examples shown in Section~\secref{nutshell} show how an FFI callout is defined in a standard method.
Upon first activation the \NB primitive will fail and by default continues to evaluate the following method body.
This is the point where \NB generates native code and attaches it to the compiled method.
\NB then reflectively resends the original message with the original arguments (for instance \ttt{abs:} in the example Figure~\figref{nativeBoostSyntax}).
On the second activation, the native code is present and thus the primitive will no fail but run the native code.
Section~\secref{nbPrimitive} will give more internal details about the code activation and triggering of code generation.

% ---------------------------------------------------------------------------
\subsubsection{Generating Assembler Instructions}

Figure \figref{nbArchitecture} shows that \NB relies on AsmJit\footnote{\url{http://smalltalkhub.com/\#!/~Pharo/AsmJit}}, a language-side assembler.
AsmJit emerged from an existing C++ implementation\footnote{\url{https://code.google.com/p/asmjit/}} and currently supports the x86 instruction set.

In fact it is even possible to inline custom assembler instructions in Pharo when using \NB.
This way it is possible to meet critical performance requirements.
Typically Smalltalk does not excel at algorithmic code since such code does not benefit from dynamic message sends.

% ---------------------------------------------------------------------------
\subsubsection{Reflective Symbiosis}

\NB lives in symbiosis with the Pharo programming environment.
As shown in the examples in Section~\secref{nutshell} and in more detail in Figure \figref{nativeBoostSyntax} \NB detects which method arguments correspond to which argument in the FFI callout.
To achieve this, \NB inspects the activation context when generating native code.
Through reflective access to the execution context we can retrieve the method's source code and thus the argument names and positions.

% ---------------------------------------------------------------------------
\subsubsection{Memory Management}

\todo{strip BENZO duplication}

\NB supports external heap management with explicit allocation and freeing of memory regions.
There are interfaces for \ttt{allocate} and \ttt{free} as well as for \ttt{memcopy}:
%
\begin{stcode}[
	label={lst:externalHeap},
	caption={Example of external heap management in \NB}]{0}
memory := NativeBoost allocate: 4.
bytes  := #[1 2 3 4].
"Fill the external memory"
NativeBoost memCopy: bytes to: memory size: 4.

"FFI call to fill the external object"
self fillExternalMemory: memory.

"Copy back bytes from the external object"
NativeBoost memCopy: memory to: bytes size: 4.
NativeBoost free: memory.
\end{stcode}

Using the external heap management it is possible to prepare binary blobs and structures for FFI calls.

In the previous example Code \lstref{externalHeap} the \ttt{memory} variable holds a wrapper for the static address of the allocated memory.
Hence accessing it from low-level code is straight forward.
However in certain situations it is required to access a high-level object from assembler.
Pharo has a moving garbage collector which means that you can not refer directly to a high-level object by a fixed address.

\begin{figure}[h]
	\centering
	\includegraphics{externalRoots}
	\caption{Pointers in a CompiledMethod to objects registered as external roots are pinpointed at fixed offset in global VM-level object. \todo{possibly remove}
	}
	\figlabel{externalRoots}
\end{figure}

To deal with this problem the VM has a special array at a known address that contains pointers to high-level objects.
The garbage collector keeps this external roots array up to date.
Hence it is possible to statically refer to a Pharo object using a double indirection over the external roots.
Figure \figref{externalRoots} visualizes how native code directly accesses Pharo objects through this indirection.


% ===========================================================================
\subsection{Activating Native Code}

In this section we present the VM-level interaction of \NB.
Even though \NB handles most tasks directly at language-side it requires certain changes on VM level:
\begin{itemize}
	\item executable memory,
	\item activation primitives for native code.
\end{itemize}
%
Since \NB manages native code at language-side there is no special structure or memory region where native code is stored.
Native instructions are appended to compiled methods which reside on the heap.
Hence the heap has to be executable in order to jump to the native instructions.


% ---------------------------------------------------------------------------
\subsubsection{The \NB activation Primitive}
\seclabel{nbPrimitive}
% - show how code is generated in several pictures
%   1. no code => enter primitive and then primFailure fallback
%   2. running NB code generation
%   3. attach the native code to the compiled method
%   4. restart method and reenter primitive, this time running the native code
% - check for the VM identifier => mismatch triggers code regeneration

\todo{strip BENZO duplication: see how much overlaps, only put a small summary here and push detailed explanation to the benzo chapter}

In Section~\secref{generating} we explained how \NB creates FFI callouts at language-side.
However, so far we left out the part on how the generated native code is activated.

The examples in Section~\secref{nutshell}, especially Figure \figref{nativeBoostSyntax} show that each \NB FFI callout requires a special primitive.
Figure \figref{nativeCodeActivation} shows how a \NB method is activated.


\begin{figure}[h]
	\centering
	\includegraphics[scale=1.1]{nativeCodeActivation}
	\caption{Native code activation. The first call triggers the code generation. Then the method is restarted and the native code executed.}
	\figlabel{nativeCodeActivation}
\end{figure}

\begin{itemize}
\item In the first step (cf. \ding{182}) the \NB callout primitive is activated.
	The primitive checks if the compiled method actually contains native code.
\item On the first activation there is no native code available yet.
	Hence the primitive will fail and the Smalltalk body (cf. \ding{183}) of the \NB method gets evaluated.
	This is where \NB prepares the native code for the FFI callout.
\item After installing the native code in the method trailer, the \NB method is reactivated with the original arguments (cf. \ding{184}).
\item Again we end up in the \NB activation primitive (cf. \ding{185}).
	However, this time there is native code (cf. \ding{186}) available and thus the primitive jumps to the native code instead.
\end{itemize}

% ---------------------------------------------------------------------------
%\subsubsection{JIT Interaction}
% - explain drawback of VM primitive approach for NB when using a JIT
% - list overhead points (context switch, not able to jit)
% - show how COG solves this for certain other primitives

% ===========================================================================
%\section{Challenges}
%\seclabel{challenge}
% ===========================================================================

% - relocatable objects access overhead (almost never happens)
% - jit interaction (solved?)
% - callbacks
% - multi threaded code (diffcult..)
% - platform independence
%   - at the user-level of NBFFI not a problem
%   - plans to introduce abstract DSL for the low-level part of NB-FFI
%   - introducing variants of ASMJit to handle the last step (generating platform specific code)

% ===========================================================================
\section{Related Work}
\seclabel{relatedWork}
% ===========================================================================
\todo{only show FFI related work here! all the abstract implementations are covered in the Benzo secrtion}
% explain typical approaches (static and dynamic)

% - need to go into detail with ALIEN
% - C-FFI for Cog
% other less related approaches: Python ctypes ? SWIG ?

Typical Smalltalk system are isolated from the low-level world and provide only limited interoperability with C libraries.
However there are notable exceptions: Étoilé and Smalltalk/X.

Chisnall presents the Pragmatic Smalltalk Compiler \cite{Chis12a}, part of the Étoilé project, which focuses on close interaction with the C world.
The main goal of this work is to reuse existing libraries and thus reduce duplicated effort.
The author highlights the expressiveness of Smalltalk to support this goal.
In this Smalltalk implementation multiple languages can be mixed efficiently.
It is possible to mix Objective-C, Smalltalk code.
All these operations can be performed dynamically at runtime.
Unlike our approach, Étoilé aims at a complete new style of runtime environment without a VM. Compared to that, \NB is a very lightweight solution.


Other dynamic high-level languages such as Lua leverage FFI performance by using a close interaction with the JIT.
LuaJIT \cite{luaffi} for instance is an efficient Lua implementation that inlines FFI calls directly into the JIT compiled code.
Similar to \NB this allows one to minimize the constant overhead by generating custom-made native code.
The LuaJIT runtime is mainly written in C which has clearly different semantics than Lua itself.


On a more abstract level, high-level low-level programming \cite{Fram09a} encourage to use high-level languages for system programming.
Frampton et al. present a low-level framework  which is used as system interface for Jikes, an experimental Java VM.
%Additionally their framework is successfully used in MMTK \cite{Blac04a} which is used independently in several other projects.
%The \ttt{org.vmmagic} package is much more elaborate than \NB but it is tailored towards Java with static types.
However their approach focuses on a static solution.
Methods have to be annotated to use low-level functionality.
Additionally the strong separation between low-level code and runtime does not allow for reflective extensions of the runtime.
Finally, they do not support the execution and not even generation of custom assembly code on the fly.


QUICKTALK \cite{Ball86a} follows a similar approach as \NB.
However Ballard et al. focus mostly on the development of a complex compiler for a new \ST dialect.
Using type annotations QUICKTALK allows for statically typing methods.
By inlining methods and eliminating the bytecode dispatch overhead by generating native code QUICKTALK outperforms interpreted bytecode methods.
%The principal goals of QUICKTALK are performance improvements on dynamic typing.
Compared to Waterfall, QUICKTALK does not allow to leave the language-side environment and interact closely with the VM.


Kell and Irwin \cite{Kell11a} take a different look at interacting with external libraries.
They advocate a Python VM that allows for dynamically shared objects with external libraries.
It uses the low-level DWARF debugging information present in the external libraries to gather enough metadata to automatically generate FFIs.

% ===========================================================================
\section{Problems}
\seclabel{problems}
% ===========================================================================
% - most problems overlap with the problems mentioned in the Benzo chapter
% - address problems on a more high-level view


\subsection{Difficult Debug Cycles}
% - debugging facility (on a higher level than Benzo, see invisible VMs)
% 	- resolve C symbols
% 	- show C source code?


\subsection{Platform Independence}
% - general / direct dependence on assembler which is not good
% - low-level platform independence solved by Benzo (link to future reference to VirtualCPU)
% - platform independence on function level (see OSEnvironment as an Example)
% 	- requires explicit subclasses
% 	- manual maintenance + singletons
% - missing support for multi-platform code definition in a single method


\subsection{Limited Expressiveness}
% - fork example is hard to achieve (vm is not directly forkable)
% - current design makes it difficult to perform more C-like operations in one run
% - adopt benzo-level abstractions on VirtualCPU



% ===========================================================================
\section{Future Work}
\seclabel{futurework}
% ===========================================================================
Even though \NB shows good overall performance when it comes to callbacks it does not keep up with other \ST-based solutions.
In the current development phase not much attention was payed to callback performance as it is not a common use case for FFI callouts.
Fast callbacks require close interaction and specific modifications at VM-level.
However, initially \NB kept the modifications to the VM at a minimum.
We assume that we can reach the same performance as Alien relying on the same low-level implementation.

As a second issue we would like to address the callout overhead by using an already existing JIT integration of \NB.
Currently the VM has to leave from JIT-mode to standard interpretation mode when it activates an \NB method.
This context switch introduces an unnecessary overhead for an FFI callout.
A current prototype directly inlines the native code of a \NB method in the JIT.
Hence the cost for the context switch plus the cost of activating the \NB callout primitive can be avoided.
% \lf{This modification aims at better integrating \NB and the JIT such as it is done in LuaJIT.}



% ===========================================================================
\section{Conclusion}
\seclabel{conclusion}
% ===========================================================================
\todo{make proper summary}
In this paper we presented \NB a novel approach to foreign function interfaces.
Our approach relies only on a very generic extension of the VM to allow for language-side code to directly call native instructions.

Using a in depth evaluation of \NB comparing against two other \ST FFI implementations and LuaJIT we showed in Section~\secref{evaluation} that our language-side approach is competitive.
\NB reduces the callout overhead by more than a factor two compared to the two closest \ST solutions.

Compared to LuaJIT there is still space for improvements.
We measured a factor 30 lower calling overhead due to a close JIT integration.
However for typical FFI calls the absolute time difference between \NB and Lua is roughly $30\%$.
With a partial solution ready to integrate \NB closer with the JIT we expect to come close to Lua's performance.

Furthermore we showed that \NB essentially combines VM-level performance with language-side flexibility when it comes to marshal complex types.
New structures are defined practically at language-side and conversion optimizations are added transparently.

% =============================================================================
\input{chapter-footer.tex}
